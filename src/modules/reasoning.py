"""
Module de Raisonnement Multi-Ã‰tapes - VERSION CORRIGÃ‰E
=====================================================
Ajout du support pour memory_context dans process_query
"""

import os
from typing import Dict, List, Optional
from dataclasses import dataclass
from groq import Groq


@dataclass
class ThinkingConfig:
    """Configuration du moteur de rÃ©flexion"""
    model_name: str = "llama-3.3-70b-versatile"
    temperature_query_rewrite: float = 0.1
    temperature_reasoning: float = 0.2
    temperature_response: float = 0.3
    max_tokens: int = 2048
    enable_verbose: bool = True


class ThinkingPrompts:
    """Templates de prompts pour chaque Ã©tape"""
    
    STAGE_1_QUERY_REWRITING = """Tu es un expert en recherche juridique dans le Code du Travail Tunisien.

{memory_context}

**QUESTION ORIGINALE DE L'UTILISATEUR:**
{user_query}

**TON OBJECTIF (Ã‰tape 1/3 - Reformuler pour recherche optimale):**

L'utilisateur pose une question en langage naturel. Tu dois la transformer en requÃªtes de recherche optimales pour trouver les articles pertinents du Code du Travail.

**ANALYSE:**
1. Quelle est la vraie question juridique?
2. Quels concepts juridiques sont concernÃ©s?
3. Quels termes juridiques prÃ©cis utiliser?
4. Quels mots-clÃ©s du Code du Travail chercher?

**FORMAT DE SORTIE:**
GÃ©nÃ¨re 3-5 requÃªtes de recherche courtes et prÃ©cises (5-10 mots max chacune).
Utilise des termes juridiques prÃ©cis du droit du travail tunisien.

IMPORTANT: Retourne UNIQUEMENT les requÃªtes, une par ligne, sans numÃ©rotation ni explications."""

    STAGE_2_LEGAL_ANALYSIS = """Tu es un assistant juridique expert en Code du Travail Tunisien.

{memory_context}

**QUESTION ORIGINALE:**
{user_query}

**ARTICLES DU CODE DU TRAVAIL TROUVÃ‰S:**
{legal_articles}

**TON ANALYSE JURIDIQUE (Ã‰tape 2/3 - Analyser situation + articles):**

Analyse la situation en profondeur:

**1. COMPRÃ‰HENSION DE LA SITUATION:**
- Quel est le contexte concret?
- Quels sont les faits importants?
- Qui sont les parties impliquÃ©es (employeur/employÃ©)?
- Quel est le vrai problÃ¨me juridique?

**2. ANALYSE DES ARTICLES:**
- Que disent prÃ©cisÃ©ment ces articles du Code du Travail?
- Comment s'appliquent-ils Ã  cette situation?
- Quelles sont les conditions et exceptions?
- Quels sont les droits et obligations de chaque partie?

**3. RAISONNEMENT JURIDIQUE:**
- Quelle est l'interprÃ©tation juridique correcte?
- Y a-t-il une violation du Code du Travail?
- Quels recours sont possibles?
- Quelles sont les consÃ©quences juridiques?

Sois rigoureux, cite les articles, et raisonne de maniÃ¨re mÃ©thodique."""

    STAGE_3_FINAL_ANSWER = """Tu es un assistant juridique expert et empathique.

{memory_context}

**QUESTION ORIGINALE:**
{user_query}

**TON ANALYSE JURIDIQUE COMPLÃˆTE:**
{legal_analysis}

**TON OBJECTIF (Ã‰tape 3/3 - RÃ©ponse finale humaine):**

Transforme ton analyse juridique en une rÃ©ponse claire, humaine et actionnable.

**STRUCTURE DE TA RÃ‰PONSE:**

1. **Introduction empathique** (2-3 phrases)
   - Reconnais la situation
   - Montre de l'empathie

2. **Explication juridique claire** (1-2 paragraphes)
   - Explique ce que dit le Code du Travail
   - Utilise un langage simple
   - Cite les articles pertinents

3. **Analyse de sa situation** (1 paragraphe)
   - Applique la loi Ã  son cas
   - Explique ses droits

4. **Conseils pratiques** (liste claire)
   - Actions concrÃ¨tes
   - Documents Ã  prÃ©parer
   - DÃ©marches Ã  suivre

5. **Conclusion rassurante** (2-3 phrases)
   - RÃ©sume les points clÃ©s
   - Recommande un avocat si nÃ©cessaire

Ã‰cris ta rÃ©ponse complÃ¨te maintenant:"""


class LegalThinkingEngine:
    """Moteur de raisonnement en 3 Ã©tapes avec support mÃ©moire"""
    
    def __init__(
        self,
        groq_api_key: Optional[str] = None,
        config: Optional[ThinkingConfig] = None
    ):
        self.config = config or ThinkingConfig()
        self.api_key = groq_api_key or os.getenv("GROQ_API_KEY")
        
        if not self.api_key:
            raise ValueError("ClÃ© API Groq manquante")
        
        self.client = Groq(api_key=self.api_key)
        self.prompts = ThinkingPrompts()
        self.thinking_chain: Dict[str, str] = {}
        
        print(f"âœ“ Thinking Engine initialisÃ© (3 Ã©tapes)")
    
    def _call_llm(
        self,
        prompt: str,
        temperature: float,
        stage_name: str
    ) -> str:
        """Appelle le LLM pour une Ã©tape"""
        
        if self.config.enable_verbose:
            print(f"\n{'='*70}")
            print(f"ðŸ§  {stage_name}")
            print(f"{'='*70}")
        
        try:
            response = self.client.chat.completions.create(
                model=self.config.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "Tu es un assistant juridique expert en Code du Travail Tunisien."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=temperature,
                max_tokens=self.config.max_tokens
            )
            
            result = response.choices[0].message.content
            
            if self.config.enable_verbose:
                preview = result[:250] + "..." if len(result) > 250 else result
                print(f"\nðŸ“ RÃ©sultat:\n{preview}\n")
            
            return result
            
        except Exception as e:
            print(f"âŒ Erreur: {e}")
            return f"[Erreur: {e}]"
    
    def stage_1_query_rewriting(self, user_query: str, memory_context: str = "") -> List[str]:
        """Ã‰tape 1: Reformuler la query avec contexte mÃ©moire"""
        prompt = self.prompts.STAGE_1_QUERY_REWRITING.format(
            user_query=user_query,
            memory_context=memory_context
        )
        result = self._call_llm(
            prompt,
            self.config.temperature_query_rewrite,
            "Ã‰TAPE 1/3 - Reformuler avec contexte conversationnel"
        )
        
        self.thinking_chain['query_rewriting'] = result
        
        queries = [
            line.strip().strip('-â€¢*"\'')
            for line in result.split('\n')
            if line.strip() and len(line.strip()) > 5
        ]
        
        queries = [q for q in queries if len(q) < 100][:5]
        
        if len(user_query) < 200:
            queries.insert(0, user_query)
        
        if self.config.enable_verbose:
            print(f"âœ“ {len(queries)} requÃªtes gÃ©nÃ©rÃ©es:")
            for i, q in enumerate(queries, 1):
                print(f"   {i}. {q}")
        
        return queries
    
    def stage_2_legal_analysis(
        self,
        user_query: str,
        legal_articles: str,
        memory_context: str = ""
    ) -> str:
        """Ã‰tape 2: Analyser avec contexte mÃ©moire"""
        prompt = self.prompts.STAGE_2_LEGAL_ANALYSIS.format(
            user_query=user_query,
            legal_articles=legal_articles,
            memory_context=memory_context
        )
        result = self._call_llm(
            prompt,
            self.config.temperature_reasoning,
            "Ã‰TAPE 2/3 - Analyser situation + articles juridiques"
        )
        
        self.thinking_chain['legal_analysis'] = result
        return result
    
    def stage_3_final_answer(
        self,
        user_query: str,
        legal_analysis: str,
        memory_context: str = ""
    ) -> str:
        """Ã‰tape 3: RÃ©ponse finale avec contexte mÃ©moire"""
        prompt = self.prompts.STAGE_3_FINAL_ANSWER.format(
            user_query=user_query,
            legal_analysis=legal_analysis,
            memory_context=memory_context
        )
        result = self._call_llm(
            prompt,
            self.config.temperature_response,
            "Ã‰TAPE 3/3 - RÃ©ponse finale humaine"
        )
        
        self.thinking_chain['final_answer'] = result
        return result
    
    def _format_articles(self, chunks: List[Dict]) -> str:
        """Formate les articles rÃ©cupÃ©rÃ©s"""
        if not chunks:
            return "[Aucun article pertinent trouvÃ©]"
        
        formatted = []
        for i, chunk in enumerate(chunks, 1):
            article = chunk.get('metadata', {}).get('article', 'Article inconnu')
            text = chunk['text']
            score = chunk.get('score', 0)
            hierarchy = chunk.get('metadata', {}).get('hierarchy_path', '')
            
            formatted.append(
                f"[Source {i}] {article} (Pertinence: {score:.2f})\n"
                f"HiÃ©rarchie: {hierarchy}\n"
                f"Contenu: {text}\n"
            )
        
        return "\n".join(formatted)
    
    def process_query(
        self,
        user_query: str,
        retriever,
        top_k: int = 8,
        memory_context: str = ""  # NOUVEAU PARAMÃˆTRE
    ) -> Dict:
        """
        Pipeline complet avec support de la mÃ©moire conversationnelle
        
        Args:
            user_query: Question originale
            retriever: Instance de CodeTravailRetriever
            top_k: Nombre d'articles
            memory_context: Contexte conversationnel formatÃ© (optionnel)
        """
        print(f"\n{'='*70}")
        print(f"ðŸš€ DÃ‰MARRAGE DU RAISONNEMENT MULTI-Ã‰TAPES")
        if memory_context:
            print("ðŸ’­ Contexte conversationnel inclus")
        print(f"{'='*70}")
        print(f"â“ Question: {user_query[:150]}...")
        
        self.thinking_chain = {'original_query': user_query}
        
        # Ã‰TAPE 1: Reformuler avec contexte mÃ©moire
        optimized_queries = self.stage_1_query_rewriting(user_query, memory_context)
        
        # RETRIEVAL
        print(f"\n{'='*70}")
        print(f"ðŸ” RECHERCHE DANS LE CODE DU TRAVAIL")
        print(f"{'='*70}")
        
        retrieved_chunks = retriever.multi_query_retrieve(
            optimized_queries,
            top_k_per_query=max(2, top_k // len(optimized_queries)),
            deduplicate=True
        )[:top_k]
        
        print(f"âœ“ {len(retrieved_chunks)} articles pertinents trouvÃ©s")
        
        if self.config.enable_verbose and retrieved_chunks:
            print(f"\nðŸ“š Articles trouvÃ©s:")
            for i, chunk in enumerate(retrieved_chunks[:3], 1):
                article = chunk.get('metadata', {}).get('article', 'N/A')
                score = chunk.get('score', 0)
                print(f"   {i}. {article} (score: {score:.2f})")
            if len(retrieved_chunks) > 3:
                print(f"   ... et {len(retrieved_chunks) - 3} autres")
        
        legal_articles = self._format_articles(retrieved_chunks)
        
        # Ã‰TAPE 2: Analyser avec contexte mÃ©moire
        legal_analysis = self.stage_2_legal_analysis(user_query, legal_articles, memory_context)
        
        # Ã‰TAPE 3: RÃ©ponse finale avec contexte mÃ©moire
        final_answer = self.stage_3_final_answer(user_query, legal_analysis, memory_context)
        
        # PrÃ©parer les sources
        sources = {}
        for i, chunk in enumerate(retrieved_chunks, 1):
            sources[str(i)] = {
                'article': chunk.get('metadata', {}).get('article', 'N/A'),
                'text': chunk['text'],
                'score': chunk.get('score', 0),
                'hierarchy': chunk.get('metadata', {}).get('hierarchy_path', '')
            }
        
        print(f"\n{'='*70}")
        print(f"âœ… RAISONNEMENT TERMINÃ‰")
        print(f"{'='*70}\n")
        
        return {
            'answer': final_answer,
            'thinking_chain': self.thinking_chain,
            'sources': sources,
            'num_sources': len(sources),
            'optimized_queries': optimized_queries,
            'question': user_query
        }
    
    def get_thinking_summary(self) -> str:
        """RÃ©sumÃ© de la chaÃ®ne de rÃ©flexion"""
        if not self.thinking_chain:
            return "Aucune rÃ©flexion disponible"
        
        summary = "\n" + "="*70 + "\n"
        summary += "ðŸ“‹ CHAÃŽNE DE RÃ‰FLEXION COMPLÃˆTE\n"
        summary += "="*70 + "\n\n"
        
        if 'original_query' in self.thinking_chain:
            summary += "â“ QUESTION ORIGINALE:\n"
            summary += f"{self.thinking_chain['original_query']}\n\n"
        
        if 'query_rewriting' in self.thinking_chain:
            summary += "1ï¸âƒ£ REFORMULATION:\n"
            summary += "-"*70 + "\n"
            summary += f"{self.thinking_chain['query_rewriting']}\n\n"
        
        if 'legal_analysis' in self.thinking_chain:
            summary += "2ï¸âƒ£ ANALYSE JURIDIQUE:\n"
            summary += "-"*70 + "\n"
            content = self.thinking_chain['legal_analysis']
            preview = content[:500] + "..." if len(content) > 500 else content
            summary += f"{preview}\n\n"
        
        if 'final_answer' in self.thinking_chain:
            summary += "3ï¸âƒ£ RÃ‰PONSE FINALE:\n"
            summary += "-"*70 + "\n"
            content = self.thinking_chain['final_answer']
            preview = content[:500] + "..." if len(content) > 500 else content
            summary += f"{preview}\n\n"
        
        return summary